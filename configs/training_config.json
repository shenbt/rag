{
  "training": {
    "general": {
      "seed": 42,
      "device": "auto",
      "num_workers": 4,
      "pin_memory": true,
      "save_interval": 5,
      "eval_interval": 2,
      "log_interval": 100
    },
    "region_encoder": {
      "model_path": "./layoutlmv3-base",
      "learning_rate": 1e-5,
      "weight_decay": 0.01,
      "warmup_steps": 1000,
      "max_grad_norm": 1.0,
      "scheduler": "cosine",
      "tasks": ["reconstruction", "classification", "alignment"]
    },
    "consistency_judge": {
      "model_name": "bert-base-chinese",
      "threshold": 0.6,
      "learning_rate": 2e-5,
      "weight_decay": 0.01,
      "warmup_steps": 500,
      "max_grad_norm": 1.0
    },
    "retriever": {
      "use_haystack": true,
      "sparse_model": "BM25",
      "dense_model": "./all-MiniLM-L6-v2",
      "cross_encoder": "./ms-marco-MiniLM-L-6-v2",
      "learning_rate": 1e-4,
      "weight_decay": 0.01
    },
    "generator": {
      "model_path": "./gpt2",
      "learning_rate": 5e-5,
      "weight_decay": 0.01,
      "warmup_steps": 1000,
      "max_grad_norm": 1.0
    },
    "pipeline": {
      "consistency_threshold": 0.6,
      "max_retries": 2,
      "evidence_top_k": 5,
      "response_timeout": 30.0
    }
  },
  "data": {
    "train_path": "./data/train_data.json",
    "val_path": "./data/val_data.json",
    "test_path": "./data/test_data.json",
    "max_length": 512,
    "batch_size": 8,
    "shuffle": true
  },
  "optimization": {
    "optimizer": "AdamW",
    "scheduler": "cosine",
    "gradient_accumulation_steps": 1,
    "early_stopping_patience": 5,
    "early_stopping_min_delta": 0.001
  },
  "checkpoints": {
    "save_dir": "./checkpoints",
    "save_best_only": true,
    "save_last": true,
    "max_checkpoints": 5
  },
  "logging": {
    "log_dir": "./logs",
    "log_level": "INFO",
    "tensorboard": true,
    "wandb": false
  },
  "evaluation": {
    "metrics": ["accuracy", "consistency", "retrieval_recall", "response_time"],
    "eval_batch_size": 16,
    "eval_steps": 1000
  }
}

