#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
UniRAGè®­ç»ƒè„šæœ¬ï¼šæ•´åˆæ‰€æœ‰åˆ›æ–°ç‚¹çš„è®­ç»ƒåŠŸèƒ½
åŒ…æ‹¬åŒºåŸŸç²’åº¦é¢„è®­ç»ƒã€ä¸€è‡´æ€§åˆ¤åˆ«è®­ç»ƒã€è¯æ®å¡è®­ç»ƒç­‰
"""

import os
import sys
import json
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from typing import Dict, List, Tuple, Optional, Any
import numpy as np
from tqdm import tqdm
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

# å¯¼å…¥åŸºç¡€åº“
import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
# å¯¼å…¥æ‰€æœ‰è®­ç»ƒéœ€è¦çš„æ¨¡å‹ç»„ä»¶
from models.encoder import RegionAwareEncoder, RegionPreTrainer
from models.consistency_judge import ConsistencyJudge
from models.evidence_cards import EvidenceCard, EvidenceCardCollection
from models.retriever import TwoStageRetriever, LayoutPlanner
from models.generator import Generator
# å¯¼å…¥æ£€ç´¢å™¨
from retrieval.indexer import HaystackRetriever
from losses.consistency_loss import ConsistencyLoss
from models.core import UniRAGPipeline
# å¯¼å…¥è‡ªå®šä¹‰æ•°æ®é›†
from dataset.datasets import OpenDocVQADataset


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class UniRAGTrainer:
    """
    UniRAGè®­ç»ƒå™¨ï¼šæ•´åˆæ‰€æœ‰ç»„ä»¶çš„è®­ç»ƒ
    """
    def __init__(self, 
                 config: Dict[str, Any],
                 device: str = "cuda" if torch.cuda.is_available() else "cpu"):
        
        self.config = config
        self.device = device
        self.logger = logger
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._init_components()
        
        # è®­ç»ƒçŠ¶æ€
        self.current_epoch = 0
        self.best_score = 0.0
        self.training_history = []
        
    def _init_components(self):
        """åˆå§‹åŒ–è®­ç»ƒç»„ä»¶"""
        try:
            # åŒºåŸŸç¼–ç å™¨
            self.encoder = RegionAwareEncoder(
                model_name=self.config.get('encoder_model_path', './layoutlmv3-base')
            ).to(self.device)
            
            # åŒºåŸŸé¢„è®­ç»ƒå™¨
            self.region_trainer = RegionPreTrainer(
                encoder=self.encoder,
                learning_rate=self.config.get('region_lr', 1e-5)
            )
            
            # ç¡®ä¿ç¼–ç å™¨åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            self.region_trainer.encoder = self.region_trainer.encoder.to(self.device)
            
            # ä¸€è‡´æ€§åˆ¤åˆ«å™¨
            self.consistency_judge = ConsistencyJudge(
                threshold=self.config.get('consistency_threshold', 0.6)
            )
            
            # ç‰ˆå¼è§„åˆ’å™¨
            self.layout_planner = LayoutPlanner()
            
            # ç”Ÿæˆå™¨
            self.generator = Generator(
                model_name=self.config.get('generator_model_path', './gpt2')
            )
            
            # è¯æ®å¡é›†åˆ
            self.evidence_cards = EvidenceCardCollection()
            
            # æ£€ç´¢å™¨
            if self.config.get('use_haystack', True):
                # ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„
                dense_model = self.config.get('model', {}).get('dense_model', './all-MiniLM-L6-v2')
                cross_encoder = self.config.get('model', {}).get('cross_encoder', './ms-marco-MiniLM-L-6-v2')
                backup_model = self.config.get('model', {}).get('backup_dense_model', './paraphrase-MiniLM-L3-v2')
                
                self.retriever = HaystackRetriever(
                    dense_model_name=dense_model,
                    cross_encoder_name=cross_encoder
                )
            else:
                self.retriever = TwoStageRetriever()
            
            # ç»Ÿä¸€ç®¡é“
            self.pipeline = UniRAGPipeline(
                retriever=self.retriever,
                layout_planner=self.layout_planner,
                generator=self.generator,
                consistency_judge=self.consistency_judge,
                evidence_cards=self.evidence_cards
            )
            
            logger.info("âœ… æ‰€æœ‰è®­ç»ƒç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def train_region_encoder(self, 
                            train_data: List[Dict[str, Any]], 
                            epochs: int = 10,
                            batch_size: int = 8) -> Dict[str, List[float]]:
        """
        è®­ç»ƒåŒºåŸŸç¼–ç å™¨ï¼šåŒºåŸŸé‡æ„ã€åˆ†ç±»ã€å¯¹é½ä»»åŠ¡
        """
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒåŒºåŸŸç¼–ç å™¨...")
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        train_loader = self._prepare_region_data(train_data, batch_size)
        
        # è®­ç»ƒå†å²
        history = {
            'reconstruction_loss': [],
            'classification_loss': [],
            'alignment_loss': []
        }
        
        for epoch in range(epochs):
            logger.info(f"ğŸ“š è®­ç»ƒè½®æ¬¡ {epoch + 1}/{epochs}")
            
            epoch_losses = {
                'reconstruction_loss': 0.0,
                'classification_loss': 0.0,
                'alignment_loss': 0.0
            }
            
            # è®­ç»ƒå¾ªç¯
            for batch_idx, batch_data in enumerate(tqdm(train_loader, desc=f"Epoch {epoch + 1}")):
                    try:
                        # é€‚é…OpenDocVQADatasetçš„è¾“å‡ºæ ¼å¼
                        if isinstance(batch_data, dict) and 'input_ids' in batch_data:
                            # è·å–æ‰¹æ¬¡å¤§å°
                            batch_size = batch_data['input_ids'].size(0)
                            
                            for sample_idx in range(batch_size):
                                # æå–å•ä¸ªæ ·æœ¬ï¼Œç¡®ä¿è®¾å¤‡ä¸€è‡´å’Œç»´åº¦æ­£ç¡®
                                input_length = batch_data['input_ids'].size(1)
                                
                                # å¤„ç†questionå’Œanswerå­—æ®µ
                                question = batch_data.get('question', [''])[sample_idx] if isinstance(batch_data.get('question'), list) else batch_data.get('question', '')
                                answer = batch_data.get('answer', [''])[sample_idx] if isinstance(batch_data.get('answer'), list) else batch_data.get('answer', '')
                                
                                # åˆå¹¶é—®é¢˜å’Œç­”æ¡ˆä½œä¸ºæ–‡æœ¬å†…å®¹
                                text_content = f"é—®é¢˜: {question} ç­”æ¡ˆ: {answer}"
                                
                                # ç¡®ä¿bboxç»´åº¦æ­£ç¡®
                                bbox = batch_data['bbox'][sample_idx:sample_idx+1].to(self.device)
                                if bbox.dim() == 3:  # [1, seq_len, 4]
                                    bbox = bbox.squeeze(0)  # [seq_len, 4]
                                
                                # è®°å½•åŸå§‹bboxä¿¡æ¯
                                original_min = torch.min(bbox).item()
                                original_max = torch.max(bbox).item()
                                
                                # ç¡®ä¿bboxåæ ‡åœ¨0-1000èŒƒå›´å†…ï¼Œå¹¶å¤„ç†å¯èƒ½çš„å¼‚å¸¸å€¼
                                bbox = torch.clamp(bbox, 0, 1000)
                                
                                # è®°å½•å¤„ç†åçš„bboxä¿¡æ¯
                                processed_min = torch.min(bbox).item()
                                processed_max = torch.max(bbox).item()
                                
                                # å¦‚æœåæ ‡è¢«æˆªæ–­ï¼Œè®°å½•è­¦å‘Š
                                if original_min < 0 or original_max > 1000:
                                    logger.warning(f"âš ï¸ æ ·æœ¬ {sample_idx} bboxåæ ‡è¢«æˆªæ–­: {original_min}-{original_max} -> {processed_min}-{processed_max}")
                                
                                # é¢å¤–çš„å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœbboxå…¨ä¸º0ï¼Œä½¿ç”¨é»˜è®¤å€¼
                                if torch.all(bbox == 0):
                                    logger.warning(f"âš ï¸ æ ·æœ¬ {sample_idx} bboxå…¨ä¸º0ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                                    bbox = torch.tensor([[0, 0, 100, 100]] * bbox.size(0), 
                                                       dtype=bbox.dtype, device=bbox.device)
                                
                                sample = {
                                    'input_ids': batch_data['input_ids'][sample_idx:sample_idx+1].to(self.device),
                                    'attention_mask': batch_data['attention_mask'][sample_idx:sample_idx+1].to(self.device),
                                    'bbox': bbox,
                                    'region_masks': torch.ones(1, input_length, device=self.device).float(),
                                    'region_labels': torch.ones(1, input_length, device=self.device).long(),
                                    'text': text_content
                                }
                                
                                # åŒºåŸŸé‡æ„è®­ç»ƒ
                                reconstruction_loss = self.region_trainer.train_reconstruction(sample)
                                epoch_losses['reconstruction_loss'] += reconstruction_loss['reconstruction_loss']
                                
                                # åŒºåŸŸåˆ†ç±»è®­ç»ƒ
                                classification_loss = self.region_trainer.train_classification(sample)
                                epoch_losses['classification_loss'] += classification_loss['classification_loss']
                                
                                # åŒºåŸŸå¯¹é½è®­ç»ƒ
                                alignment_loss = self.region_trainer.train_alignment(sample)
                                epoch_losses['alignment_loss'] += alignment_loss['alignment_loss']
                        
                        else:
                            # å…¶ä»–æ ¼å¼ï¼šç›´æ¥å¤„ç†
                            logger.warning(f"âš ï¸ æœªçŸ¥çš„batch_dataæ ¼å¼ï¼Œè·³è¿‡æ‰¹æ¬¡ {batch_idx}")
                            continue
                    
                    except Exception as e:
                        logger.warning(f"âš ï¸ æ‰¹æ¬¡ {batch_idx} è®­ç»ƒå¤±è´¥: {e}")
                        continue
            
            # è®¡ç®—å¹³å‡æŸå¤±
            num_batches = len(train_loader)
            for key in epoch_losses:
                epoch_losses[key] /= num_batches
                history[key].append(epoch_losses[key])
            
            # è®°å½•è®­ç»ƒè¿›åº¦
            logger.info(f"è½®æ¬¡ {epoch + 1} æŸå¤±: {epoch_losses}")
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % self.config.get('save_interval', 5) == 0:
                self._save_checkpoint(f"region_encoder_epoch_{epoch + 1}.pt")
        
        logger.info("âœ… åŒºåŸŸç¼–ç å™¨è®­ç»ƒå®Œæˆ")
        return history
    
    def _prepare_region_data(self, data: List[Dict[str, Any]], 
                            batch_size: int) -> DataLoader:
        """å‡†å¤‡åŒºåŸŸè®­ç»ƒæ•°æ®ï¼Œä½¿ç”¨OpenDocVQADataset"""
        try:
            # è·å–æ•°æ®ç›®å½•
            data_dir = self.config['data']['path']
            
            # åˆå§‹åŒ–tokenizerï¼ˆä½¿ç”¨LayoutLMv3çš„tokenizerï¼‰
            from transformers import LayoutLMv3Tokenizer
            tokenizer = LayoutLMv3Tokenizer.from_pretrained("microsoft/layoutlmv3-base")
            
            # åˆ›å»ºOpenDocVQADatasetå®ä¾‹
            dataset = OpenDocVQADataset(data_dir, tokenizer)
            
            logger.info(f"ğŸ“Š ä½¿ç”¨OpenDocVQADatasetåŠ è½½äº† {len(dataset)} ä¸ªè®­ç»ƒæ ·æœ¬")
            
            # ç›´æ¥è¿”å›DataLoaderï¼Œè®©PyTorchå¤„ç†æ‰¹æ¬¡
            return DataLoader(dataset, batch_size=batch_size, shuffle=True)
            
        except Exception as e:
            logger.warning(f"âš ï¸ OpenDocVQADatasetåˆå§‹åŒ–å¤±è´¥: {e}")
            logger.info("ğŸ”„ å›é€€åˆ°åŸå§‹æ•°æ®å¤„ç†æ–¹æ³•...")
            
            # å›é€€æ–¹æ³•ï¼šåŸå§‹æ•°æ®å¤„ç†
            processed_data = []
            
            for item in data:
                # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„å­—æ®µ
                has_ocr = 'ocr' in item and item['ocr']
                has_bbox = 'bbox' in item and item['bbox']
                
                if has_ocr and has_bbox:
                    # å°†OCRæ–‡æœ¬åˆå¹¶ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²
                    text_content = ' '.join(item['ocr']) if isinstance(item['ocr'], list) else str(item['ocr'])
                    
                    # ä¸ºæ¯ä¸ªæ ·æœ¬åˆ›å»ºç»Ÿä¸€çš„è®­ç»ƒæ•°æ®ç»“æ„
                    processed_data.append({
                        'input_ids': torch.randint(0, 1000, (10,), device=self.device),
                        'attention_mask': torch.ones(10, device=self.device),
                        'bbox': torch.tensor([0, 0, 100, 100], device=self.device),  # ä½¿ç”¨å®‰å…¨çš„é»˜è®¤å€¼
                        'region_masks': torch.ones(10, device=self.device).float(),
                        'text': text_content,
                        'region_labels': torch.tensor([0], device=self.device),
                        'task_type': 'combined'
                    })
            
            logger.info(f"ğŸ“Š ä½¿ç”¨å›é€€æ–¹æ³•å¤„ç†äº† {len(processed_data)} ä¸ªåŒºåŸŸè®­ç»ƒæ ·æœ¬")
            
            if not processed_data:
                logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åŒºåŸŸè®­ç»ƒæ•°æ®ï¼Œåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®")
                # åˆ›å»ºä¸€äº›æ¨¡æ‹Ÿæ•°æ®ä»¥é¿å…ç©ºæ•°æ®é›†é”™è¯¯
                for i in range(max(1, batch_size)):
                    processed_data.append({
                        'input_ids': torch.randint(0, 1000, (10,), device=self.device),
                        'attention_mask': torch.ones(10, device=self.device),
                        'bbox': torch.tensor([0, 0, 100, 100], device=self.device),
                        'region_masks': torch.ones(10, device=self.device).float(),
                        'text': f"æ¨¡æ‹Ÿæ–‡æœ¬ {i}",
                        'region_labels': torch.tensor([i % 10], device=self.device),
                        'task_type': 'combined'
                    })
            
            return DataLoader(processed_data, batch_size=batch_size, shuffle=True)
    
    def train_consistency_judge(self, 
                               train_data: List[Dict[str, Any]], 
                               epochs: int = 5) -> Dict[str, List[float]]:
        """
        è®­ç»ƒä¸€è‡´æ€§åˆ¤åˆ«å™¨
        """
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒä¸€è‡´æ€§åˆ¤åˆ«å™¨...")
        
        # è¿™é‡Œå¯ä»¥å®ç°ä¸€è‡´æ€§åˆ¤åˆ«å™¨çš„è®­ç»ƒé€»è¾‘
        # ç”±äºå½“å‰å®ç°æ˜¯åŸºäºè§„åˆ™çš„ï¼Œè¿™é‡Œä¸»è¦è¿›è¡Œå‚æ•°è°ƒä¼˜
        
        history = {'consistency_score': []}
        
        for epoch in range(epochs):
            logger.info(f"ğŸ“š è®­ç»ƒè½®æ¬¡ {epoch + 1}/{epochs}")
            
            # è¯„ä¼°å½“å‰é˜ˆå€¼ä¸‹çš„æ€§èƒ½
            scores = []
            for item in train_data:
                if 'question' in item and 'answer' in item and 'evidence' in item:
                    result = self.consistency_judge.check(item['answer'], item['evidence'])
                    scores.append(result['overall_score'])
            
            if scores:
                avg_score = np.mean(scores)
                history['consistency_score'].append(avg_score)
                logger.info(f"è½®æ¬¡ {epoch + 1} å¹³å‡ä¸€è‡´æ€§è¯„åˆ†: {avg_score:.3f}")
                
                # åŠ¨æ€è°ƒæ•´é˜ˆå€¼
                if avg_score < 0.6:
                    new_threshold = max(0.4, self.consistency_judge.threshold - 0.05)
                    self.consistency_judge.adjust_threshold(new_threshold)
                    logger.info(f"è°ƒæ•´ä¸€è‡´æ€§é˜ˆå€¼åˆ°: {new_threshold}")
        
        logger.info("âœ… ä¸€è‡´æ€§åˆ¤åˆ«å™¨è®­ç»ƒå®Œæˆ")
        return history
    
    def train_retriever(self, 
                       train_data: List[Dict[str, Any]], 
                       epochs: int = 3) -> Dict[str, List[float]]:
        """
        è®­ç»ƒæ£€ç´¢å™¨ï¼šä¼˜åŒ–æ£€ç´¢å‚æ•°å’Œæ¨¡å‹
        """
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒæ£€ç´¢å™¨...")
        
        history = {'retrieval_accuracy': []}
        
        for epoch in range(epochs):
            logger.info(f"ğŸ“š è®­ç»ƒè½®æ¬¡ {epoch + 1}/{epochs}")
            
            # è¯„ä¼°æ£€ç´¢æ€§èƒ½
            accuracies = []
            for item in train_data:
                if 'question' in item and 'relevant_docs' in item:
                    # æ‰§è¡Œæ£€ç´¢
                    if isinstance(self.retriever, HaystackRetriever):
                        evidence_cards = self.retriever.retrieve(item['question'])
                    else:
                        query_embedding = self.encoder.encode_text(item['question'])
                        evidence_cards = self.retriever.retrieve(query_embedding, item['question'])
                    
                    # è®¡ç®—æ£€ç´¢å‡†ç¡®ç‡
                    if evidence_cards:
                        retrieved_docs = [card.page_id for card in evidence_cards.get_top_cards(5)]
                        relevant_docs = item['relevant_docs']
                        
                        # è®¡ç®—å¬å›ç‡
                        recall = len(set(retrieved_docs) & set(relevant_docs)) / len(relevant_docs)
                        accuracies.append(recall)
            
            if accuracies:
                avg_accuracy = np.mean(accuracies)
                history['retrieval_accuracy'].append(avg_accuracy)
                logger.info(f"è½®æ¬¡ {epoch + 1} å¹³å‡æ£€ç´¢å‡†ç¡®ç‡: {avg_accuracy:.3f}")
        
        logger.info("âœ… æ£€ç´¢å™¨è®­ç»ƒå®Œæˆ")
        return history
    
    def train_full_pipeline(self, 
                           train_data: List[Dict[str, Any]], 
                           epochs: int = 5) -> Dict[str, List[float]]:
        """
        è®­ç»ƒå®Œæ•´ç®¡é“ï¼šç«¯åˆ°ç«¯ä¼˜åŒ–ï¼ˆé¿å…é‡å¤è®­ç»ƒï¼‰
        """
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒå®Œæ•´ç®¡é“...")
        
        # åˆå§‹åŒ–ç®¡é“
        documents = []
        for item in train_data:
            if 'document' in item:
                documents.append(item['document'])
        
        self.pipeline.initialize(documents)
        
        history = {
            'pipeline_accuracy': [],
            'response_time': []
        }
        
        for epoch in range(epochs):
            logger.info(f"ğŸ“š è®­ç»ƒè½®æ¬¡ {epoch + 1}/{epochs}")
            
            epoch_metrics = {
                'accuracy': [],
                'response_time': []
            }
            
            # è®­ç»ƒå¾ªç¯ - åªè¿›è¡Œç«¯åˆ°ç«¯ä¼˜åŒ–ï¼Œä¸é‡å¤æ£€ç´¢å’Œä¸€è‡´æ€§è®­ç»ƒ
            for item in tqdm(train_data, desc=f"Epoch {epoch + 1}"):
                if 'question' in item and 'expected_answer' in item:
                    try:
                        # æ‰§è¡ŒæŸ¥è¯¢ï¼ˆä½¿ç”¨å·²è®­ç»ƒçš„ç»„ä»¶ï¼‰
                        result = self.pipeline.query(item['question'])
                        
                        # è®°å½•æŒ‡æ ‡
                        epoch_metrics['accuracy'].append(1.0 if result['success'] else 0.0)
                        epoch_metrics['response_time'].append(result.get('response_time', 0.0))
                        
                    except Exception as e:
                        logger.warning(f"âš ï¸ æŸ¥è¯¢å¤±è´¥: {e}")
                        continue
            
            # è®¡ç®—å¹³å‡æŒ‡æ ‡
            for key in epoch_metrics:
                if epoch_metrics[key]:
                    avg_value = np.mean(epoch_metrics[key])
                    history[f'pipeline_{key}'].append(avg_value)
                    logger.info(f"è½®æ¬¡ {epoch + 1} å¹³å‡{key}: {avg_value:.3f}")
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % self.config.get('save_interval', 2) == 0:
                self._save_checkpoint(f"full_pipeline_epoch_{epoch + 1}.pt")
        
        logger.info("âœ… å®Œæ•´ç®¡é“è®­ç»ƒå®Œæˆ")
        return history
    
    def train_reasoning_sft(self, 
                           train_data: List[Dict[str, Any]], 
                           epochs: int = 5,
                           batch_size: int = 8) -> Dict[str, List[float]]:
        """
        è®­ç»ƒæ¨ç†SFTï¼šå››æ­¥æ¨ç†é“¾è®­ç»ƒ
        """
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒæ¨ç†SFT...")
        
        try:
            # ä½¿ç”¨æ‚¨çš„OpenDocVQADataset
            from transformers import LayoutLMv3Tokenizer
            
            # åˆå§‹åŒ–tokenizer
            tokenizer = LayoutLMv3Tokenizer.from_pretrained("microsoft/layoutlmv3-base")
            
            # åˆ›å»ºæ•°æ®åŠ è½½å™¨
            from torch.utils.data import DataLoader
            data_dir = self.config['data']['path']
            dataset = OpenDocVQADataset(data_dir, tokenizer)
            train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
            
            # è®­ç»ƒå†å²
            history = {
                'format_loss': [],
                'consistency_loss': [],
                'total_loss': []
            }
            
            # ä¼˜åŒ–å™¨
            optimizer = torch.optim.AdamW(self.generator.parameters(), lr=1e-5)
            
            for epoch in range(epochs):
                logger.info(f"ğŸ“š è®­ç»ƒè½®æ¬¡ {epoch + 1}/{epochs}")
                
                epoch_losses = {
                    'format_loss': 0.0,
                    'consistency_loss': 0.0,
                    'total_loss': 0.0
                }
                
                # è®­ç»ƒå¾ªç¯
                for batch_idx, batch_data in enumerate(tqdm(train_loader, desc=f"Epoch {epoch + 1}")):
                    try:
                        # é€‚é…OpenDocVQADatasetçš„è¾“å‡ºæ ¼å¼
                        batch_size = batch_data['input_ids'].size(0)
                        
                        # è·å–è®­ç»ƒç›®æ ‡
                        target_texts = []
                        generated_outputs = []
                        
                        for i in range(batch_size):
                            # è·å–é—®é¢˜å’Œç­”æ¡ˆ
                            question = batch_data.get('question', [''])[i] if isinstance(batch_data.get('question'), list) else batch_data.get('question', '')
                            answer = batch_data.get('answer', [''])[i] if isinstance(batch_data.get('answer'), list) else batch_data.get('answer', '')
                            
                            # æ„å»ºæ¨ç†æç¤ºè¯
                            prompt = f"""è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯è¿›è¡Œå››æ­¥æ¨ç†ï¼š

é—®é¢˜ï¼š{question}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

<think>
åŸºäºé—®é¢˜"{question}"è¿›è¡Œåˆ†æï¼š
1. é—®é¢˜ç†è§£ï¼šéœ€è¦ä»è¯æ®ä¸­æå–ç›¸å…³ä¿¡æ¯
2. è¯æ®åˆ†æï¼šè¯æ®åŒ…å«å…³é”®ä¿¡æ¯
3. ç­”æ¡ˆæ–¹å‘ï¼šåŸºäºè¯æ®å†…å®¹ç¡®å®šç­”æ¡ˆ
4. éªŒè¯éœ€æ±‚ï¼šå¯èƒ½éœ€è¦è¿›ä¸€æ­¥ç¡®è®¤
</think>

<tool>
å·¥å…·ï¼šOCRè¯†åˆ«
è¾“å…¥ï¼š{question}
è¾“å‡ºï¼šç›¸å…³æ–‡æœ¬å†…å®¹
ç½®ä¿¡åº¦ï¼š0.85
</tool>

<rethink>
é‡æ–°åˆ†æé—®é¢˜"{question}"ï¼š
1. å·¥å…·ç»“æœéªŒè¯ï¼šè¯æ®å†…å®¹å‡†ç¡®
2. ä¸€è‡´æ€§æ£€æŸ¥ï¼šå·¥å…·è¾“å‡ºä¸åŸå§‹åˆ†æä¸€è‡´
3. è°ƒæ•´å»ºè®®ï¼šæ— éœ€è°ƒæ•´
4. ç½®ä¿¡åº¦ï¼š0.9
</rethink>

<answer>
{answer}
</answer>"""
                            
                            # ç”Ÿæˆæ¨ç†è¾“å‡º
                            output = self.generator.generate(
                                prompt=prompt,
                                mode="rethink_answer",
                                max_length=1024
                            )
                            generated_outputs.append(output)
                            
                            # æ„å»ºç›®æ ‡æ–‡æœ¬
                            target = f"""<think>
åŸºäºé—®é¢˜"{question}"è¿›è¡Œåˆ†æï¼š
1. é—®é¢˜ç†è§£ï¼šéœ€è¦ä»è¯æ®ä¸­æå–ç›¸å…³ä¿¡æ¯
2. è¯æ®åˆ†æï¼šè¯æ®åŒ…å«å…³é”®ä¿¡æ¯
3. ç­”æ¡ˆæ–¹å‘ï¼šåŸºäºè¯æ®å†…å®¹ç¡®å®šç­”æ¡ˆ
4. éªŒè¯éœ€æ±‚ï¼šå¯èƒ½éœ€è¦è¿›ä¸€æ­¥ç¡®è®¤
</think>

<tool>
å·¥å…·ï¼šOCRè¯†åˆ«
è¾“å…¥ï¼š{question}
è¾“å‡ºï¼šç›¸å…³æ–‡æœ¬å†…å®¹
ç½®ä¿¡åº¦ï¼š0.85
</tool>

<rethink>
é‡æ–°åˆ†æé—®é¢˜"{question}"ï¼š
1. å·¥å…·ç»“æœéªŒè¯ï¼šè¯æ®å†…å®¹å‡†ç¡®
2. ä¸€è‡´æ€§æ£€æŸ¥ï¼šå·¥å…·è¾“å‡ºä¸åŸå§‹åˆ†æä¸€è‡´
3. è°ƒæ•´å»ºè®®ï¼šæ— éœ€è°ƒæ•´
4. ç½®ä¿¡åº¦ï¼š0.9
</rethink>

<answer>
{answer}
</answer>"""
                            target_texts.append(target)
                        
                        # è®¡ç®—æ ¼å¼æŸå¤±
                        format_loss = self._calculate_format_loss(generated_outputs, target_texts)
                        
                        # è®¡ç®—ä¸€è‡´æ€§æŸå¤±
                        consistency_loss = self._calculate_consistency_loss(generated_outputs, batch_data)
                        
                        # æ€»æŸå¤±
                        total_loss = format_loss + 0.3 * consistency_loss
                        
                        # åå‘ä¼ æ’­
                        optimizer.zero_grad()
                        total_loss.backward()
                        optimizer.step()
                        
                        # è®°å½•æŸå¤±
                        epoch_losses['format_loss'] += format_loss.item()
                        epoch_losses['consistency_loss'] += consistency_loss.item()
                        epoch_losses['total_loss'] += total_loss.item()
                        
                    except Exception as e:
                        logger.warning(f"âš ï¸ æ‰¹æ¬¡ {batch_idx} è®­ç»ƒå¤±è´¥: {e}")
                        continue
                
                # è®¡ç®—å¹³å‡æŸå¤±
                num_batches = len(train_loader)
                for key in epoch_losses:
                    epoch_losses[key] /= num_batches
                    history[key].append(epoch_losses[key])
                
                # è®°å½•è®­ç»ƒè¿›åº¦
                logger.info(f"è½®æ¬¡ {epoch + 1} æŸå¤±: {epoch_losses}")
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                if (epoch + 1) % self.config.get('save_interval', 2) == 0:
                    self._save_checkpoint(f"reasoning_sft_epoch_{epoch + 1}.pt")
            
            logger.info("âœ… æ¨ç†SFTè®­ç»ƒå®Œæˆ")
            return history
            
        except Exception as e:
            logger.error(f"âŒ æ¨ç†SFTè®­ç»ƒå¤±è´¥: {e}")
            return {'format_loss': [], 'consistency_loss': [], 'total_loss': []}
    
    def _calculate_format_loss(self, generated_outputs: List[str], target_texts: List[str]) -> torch.Tensor:
        """è®¡ç®—æ ¼å¼æŸå¤±"""
        format_loss = 0.0
        
        for generated, target in zip(generated_outputs, target_texts):
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦çš„æ ‡ç­¾
            required_tags = ['<think>', '</think>', '<tool>', '</tool>', '<rethink>', '</rethink>', '<answer>', '</answer>']
            
            for tag in required_tags:
                if tag not in generated:
                    format_loss += 1.0  # ç¼ºå¤±æ ‡ç­¾çš„æƒ©ç½š
        
        return torch.tensor(format_loss, requires_grad=True)
    
    def _calculate_consistency_loss(self, generated_outputs: List[str], batch_data: Dict) -> torch.Tensor:
        """è®¡ç®—ä¸€è‡´æ€§æŸå¤±"""
        consistency_loss = 0.0
        
        for i, output in enumerate(generated_outputs):
            # æå–ç”Ÿæˆçš„ç­”æ¡ˆ
            answer_start = output.find('<answer>')
            answer_end = output.find('</answer>')
            
            if answer_start != -1 and answer_end != -1:
                generated_answer = output[answer_start + 8:answer_end].strip()
                
                # è·å–åŸå§‹ç­”æ¡ˆ
                original_answer = batch_data.get('answer', [''])[i] if isinstance(batch_data.get('answer'), list) else batch_data.get('answer', '')
                
                # è®¡ç®—ç­”æ¡ˆä¸€è‡´æ€§
                if generated_answer != original_answer:
                    consistency_loss += 1.0
        
        return torch.tensor(consistency_loss, requires_grad=True)
    
    def _save_checkpoint(self, filename: str):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        try:
            checkpoint_path = os.path.join(self.config.get('checkpoint_dir', './checkpoints'), filename)
            os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)
            
            checkpoint = {
                'epoch': self.current_epoch,
                'best_score': self.best_score,
                'training_history': self.training_history,
                'config': self.config
            }
            
            # å®‰å…¨åœ°ä¿å­˜æ¨¡å‹çŠ¶æ€ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒstate_dictï¼‰
            try:
                if hasattr(self.encoder, 'state_dict'):
                    checkpoint['encoder_state_dict'] = self.encoder.state_dict()
                else:
                    checkpoint['encoder_state_dict'] = None
                    logger.info("â„¹ï¸ ç¼–ç å™¨ä¸æ”¯æŒstate_dictï¼Œè·³è¿‡æ¨¡å‹çŠ¶æ€ä¿å­˜")
            except Exception as e:
                logger.warning(f"âš ï¸ ä¿å­˜ç¼–ç å™¨çŠ¶æ€å¤±è´¥: {e}")
                checkpoint['encoder_state_dict'] = None
            
            torch.save(checkpoint, checkpoint_path)
            logger.info(f"âœ… æ£€æŸ¥ç‚¹å·²ä¿å­˜åˆ° {checkpoint_path}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    
    def load_checkpoint(self, checkpoint_path: str):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        try:
            checkpoint = torch.load(checkpoint_path, map_location=self.device)
            
            self.current_epoch = checkpoint['epoch']
            self.best_score = checkpoint['best_score']
            self.training_history = checkpoint['training_history']
            
            # å®‰å…¨åœ°åŠ è½½æ¨¡å‹çŠ¶æ€
            if 'encoder_state_dict' in checkpoint and checkpoint['encoder_state_dict'] is not None:
                try:
                    if hasattr(self.encoder, 'load_state_dict'):
                        self.encoder.load_state_dict(checkpoint['encoder_state_dict'])
                        logger.info("âœ… ç¼–ç å™¨çŠ¶æ€å·²æ¢å¤")
                    else:
                        logger.info("â„¹ï¸ ç¼–ç å™¨ä¸æ”¯æŒload_state_dictï¼Œè·³è¿‡çŠ¶æ€æ¢å¤")
                except Exception as e:
                    logger.warning(f"âš ï¸ æ¢å¤ç¼–ç å™¨çŠ¶æ€å¤±è´¥: {e}")
            else:
                logger.info("â„¹ï¸ æ£€æŸ¥ç‚¹ä¸­æ²¡æœ‰ç¼–ç å™¨çŠ¶æ€ï¼Œè·³è¿‡çŠ¶æ€æ¢å¤")
            
            logger.info(f"âœ… æ£€æŸ¥ç‚¹å·²ä» {checkpoint_path} åŠ è½½")
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    
    def evaluate(self, test_data: List[Dict[str, Any]]) -> Dict[str, float]:
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        """
        logger.info("ğŸ” å¼€å§‹è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
        
        metrics = {
            'retrieval_accuracy': 0.0,
            'consistency_score': 0.0,
            'pipeline_accuracy': 0.0,
            'avg_response_time': 0.0
        }
        
        # è¯„ä¼°æ£€ç´¢æ€§èƒ½
        retrieval_scores = []
        consistency_scores = []
        pipeline_scores = []
        response_times = []
        
        for item in test_data:
            if 'question' in item:
                try:
                    # æ‰§è¡ŒæŸ¥è¯¢
                    result = self.pipeline.query(item['question'])
                    
                    # è®°å½•æŒ‡æ ‡
                    pipeline_scores.append(1.0 if result['success'] else 0.0)
                    
                    # å®‰å…¨åœ°è·å–ä¸€è‡´æ€§è¯„åˆ†
                    if result['success'] and 'consistency_score' in result:
                        consistency_scores.append(result['consistency_score'])
                    else:
                        consistency_scores.append(0.0)  # é»˜è®¤å€¼
                    
                    # å®‰å…¨åœ°è·å–å“åº”æ—¶é—´
                    if 'response_time' in result:
                        response_times.append(result['response_time'])
                    else:
                        response_times.append(0.0)  # é»˜è®¤å€¼
                    
                    # è¯„ä¼°æ£€ç´¢æ€§èƒ½ï¼ˆå¦‚æœæœ‰ç›¸å…³æ–‡æ¡£ä¿¡æ¯ï¼‰
                    if 'relevant_docs' in item and result['success'] and 'evidence_cards' in result:
                        evidence_cards = result['evidence_cards']
                        if hasattr(evidence_cards, 'get_all_cards'):
                            retrieved_docs = [card.page_id for card in evidence_cards.get_all_cards()]
                        else:
                            retrieved_docs = []
                        
                        relevant_docs = item['relevant_docs']
                        
                        if relevant_docs and retrieved_docs:
                            recall = len(set(retrieved_docs) & set(relevant_docs)) / len(relevant_docs)
                            retrieval_scores.append(recall)
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯„ä¼°å¤±è´¥: {e}")
                    continue
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        if retrieval_scores:
            metrics['retrieval_accuracy'] = np.mean(retrieval_scores)
        if consistency_scores:
            metrics['consistency_score'] = np.mean(consistency_scores)
        if pipeline_scores:
            metrics['pipeline_accuracy'] = np.mean(pipeline_scores)
        if response_times:
            metrics['avg_response_time'] = np.mean(response_times)
        
        logger.info(f"ğŸ“Š è¯„ä¼°ç»“æœ: {metrics}")
        return metrics


def main():
    """ä¸»å‡½æ•°ï¼šç›´æ¥è¯»å–é…ç½®æ–‡ä»¶å¹¶å¯åŠ¨è®­ç»ƒ"""
    # é…ç½®æ–‡ä»¶è·¯å¾„
    config_path = "configs/configs.yaml"
    
    # åŠ è½½é…ç½®
    try:
        import yaml
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        logger.info(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
    except ImportError:
        logger.warning("âš ï¸ PyYAMLæœªå®‰è£…ï¼Œå°è¯•ä½¿ç”¨JSONæ ¼å¼")
        try:
            with open(config_path.replace('.yaml', '.json'), 'r', encoding='utf-8') as f:
                config = json.load(f)
            logger.info(f"âœ… æˆåŠŸåŠ è½½JSONé…ç½®æ–‡ä»¶")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return
    except Exception as e:
        logger.error(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # è®¾ç½®é»˜è®¤å€¼
    default_config = {
        'task': 'all',
        'epochs': 5,
        'batch_size': 16,
        'checkpoint_dir': './checkpoints',
        'resume': None,
        'use_haystack': True,
        'consistency_threshold': 0.6,
        'encoder_model_path': './layoutlmv3-base',
        'generator_model_path': './gpt2'
    }
    
    # åˆå¹¶é…ç½®
    for key, value in default_config.items():
        if key not in config:
            config[key] = value
    
    logger.info(f"ğŸ“Š è®­ç»ƒé…ç½®:")
    logger.info(f"   ä»»åŠ¡ç±»å‹: {config['task']}")
    logger.info(f"   è®­ç»ƒè½®æ•°: {config['epochs']}")
    logger.info(f"   æ‰¹æ¬¡å¤§å°: {config['batch_size']}")
    logger.info(f"   æ•°æ®è·¯å¾„: {config['data']['path']}")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = UniRAGTrainer(config)
    
    # åŠ è½½æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if config.get('resume'):
        trainer.load_checkpoint(config['resume'])
    
    # åŠ è½½è®­ç»ƒæ•°æ®
    try:
        data_dir = config['data']['path']
        train_split = config['data'].get('train_split', 'train.json')
        
        # æ„å»ºå®Œæ•´çš„è®­ç»ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        if os.path.isdir(data_dir):
            train_data_path = os.path.join(data_dir, train_split)
            logger.info(f"ğŸ“ æ•°æ®ç›®å½•: {data_dir}")
            logger.info(f"ğŸ“„ è®­ç»ƒæ–‡ä»¶: {train_data_path}")
        else:
            train_data_path = data_dir
            logger.info(f"ğŸ“„ è®­ç»ƒæ–‡ä»¶: {train_data_path}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(train_data_path):
            logger.error(f"âŒ è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {train_data_path}")
            logger.info("ğŸ’¡ è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„data.pathå’Œdata.train_splitè®¾ç½®")
            return
        
        # è¯»å–è®­ç»ƒæ•°æ®
        with open(train_data_path, 'r', encoding='utf-8') as f:
            train_data = json.load(f)
        logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(train_data)} æ¡è®­ç»ƒæ•°æ®")
        
    except Exception as e:
        logger.error(f"âŒ åŠ è½½è®­ç»ƒæ•°æ®å¤±è´¥: {e}")
        logger.info("ğŸ’¡ è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶æ ¼å¼æ­£ç¡®ä¸”è·¯å¾„æœ‰æ•ˆ")
        return
    
    # å¼€å§‹è®­ç»ƒ
    try:
        # æŒ‰é¡ºåºè®­ç»ƒï¼Œé¿å…é‡å¤
        if config['task'] == 'region_encoder' or config['task'] == 'all':
            logger.info("ğŸ¯ è®­ç»ƒåŒºåŸŸç¼–ç å™¨...")
            history = trainer.train_region_encoder(train_data, config['epochs'], config['batch_size'])
            trainer.training_history.append(('region_encoder', history))
        
        if config['task'] == 'consistency_judge' or config['task'] == 'all':
            logger.info("ğŸ¯ è®­ç»ƒä¸€è‡´æ€§åˆ¤åˆ«å™¨...")
            history = trainer.train_consistency_judge(train_data, config['epochs'])
            trainer.training_history.append(('consistency_judge', history))
        
        if config['task'] == 'retriever' or config['task'] == 'all':
            logger.info("ğŸ¯ è®­ç»ƒæ£€ç´¢å™¨...")
            history = trainer.train_retriever(train_data, config['epochs'])
            trainer.training_history.append(('retriever', history))
        
        # å®Œæ•´ç®¡é“è®­ç»ƒåªåœ¨å•ç‹¬ä»»åŠ¡æ—¶æ‰§è¡Œï¼Œé¿å…é‡å¤
        if config['task'] == 'full_pipeline':
            logger.info("ğŸ¯ è®­ç»ƒå®Œæ•´ç®¡é“...")
            history = trainer.train_full_pipeline(train_data, config['epochs'])
            trainer.training_history.append(('full_pipeline', history))
        elif config['task'] == 'reasoning_sft':
            logger.info("ğŸ¯ è®­ç»ƒæ¨ç†SFT...")
            history = trainer.train_reasoning_sft(train_data, config['epochs'], config['batch_size'])
            trainer.training_history.append(('reasoning_sft', history))
        elif config['task'] == 'all':
            # åœ¨'all'æ¨¡å¼ä¸‹ï¼Œåªè¿›è¡Œç«¯åˆ°ç«¯è¯„ä¼°ï¼Œä¸é‡å¤è®­ç»ƒ
            logger.info("ğŸ¯ è¿›è¡Œç«¯åˆ°ç«¯è¯„ä¼°...")
            metrics = trainer.evaluate(train_data[:50])  # ä½¿ç”¨å°‘é‡æ•°æ®è¿›è¡Œè¯„ä¼°
            trainer.training_history.append(('evaluation', metrics))
        
        # ä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹
        trainer._save_checkpoint("final_checkpoint.pt")
        
        logger.info("ğŸ‰ æ‰€æœ‰è®­ç»ƒä»»åŠ¡å®Œæˆï¼")
        
        # è¯„ä¼°æ¨¡å‹
        logger.info("ğŸ” å¼€å§‹è¯„ä¼°æ¨¡å‹...")
        metrics = trainer.evaluate(train_data[:100])  # ä½¿ç”¨å‰100æ¡æ•°æ®è¯„ä¼°
        
        # ä¿å­˜è®­ç»ƒç»“æœ
        results = {
            'training_history': trainer.training_history,
            'final_metrics': metrics,
            'config': config,
            'timestamp': datetime.now().isoformat()
        }
        
        with open('training_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        logger.info("âœ… è®­ç»ƒç»“æœå·²ä¿å­˜åˆ° training_results.json")
        
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
